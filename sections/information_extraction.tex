\chapter{Information extraction}
% what is this chapter about

\section{Overview}
The goal of the information extraction component is to obtain useful information from incoming messages. The main tasks performed by this component are named-entity recognition, email extraction, HTML removal, header parsing, quoted text removal and relationship disambiguation. Because this component is the first processing step after entry into the system, it is equipped with methods to deal with potentially dirty data [SECTION]. Once relevant information is extracted, the result is passed as input to the response generation component and is used to generate a convicing, human-like response. For example, the outputs of the named-entity recognition (NER) task might be used to compose a personalized greeting in the beginning of the message -- e.g., ``\textit{Hello John}''.

\section{Implementation}
In order to extract the information we are interested in, we apply a series of transformations to each incoming message. These steps are summarized in the algorithm below:
\begin{enumerate}
\item remove HTML % 1
\vspace{-5mm}
\item remove any quoted messages % 2 
\vspace{-5mm}
\item cleanse headers % 3
\vspace{-5mm}
\item extract \textit{From, Reply-To, Subject, To} headers % 4
\vspace{-5mm}
\item extract message body % 5
\vspace{-5mm}
\item perform NER on the message body % 6
\vspace{-5mm}
\item extract all emails from the message body % 7
\vspace{-5mm}
\item compute relationships between emails and named-entities %8 
\end{enumerate}

The implementation of steps1--4 and how we deal with dirty data is discussed in [SECTION]. Similarly, in [SECTION] we outline our approach to named-entity recognition and the computation of the named-entity, email pairs.

\subsection{Dealing with dirty data}
As we explained in [CHAPTER], a web crawler is one of the main sources of new email messages for our system. Whilst this aids automation, it also creates a number of problems. First, because messages are posted by human forum participants, they rarely conform to MIME or any other RFC memoranda. The lack of standartization makes it impossible to rely on a standard, compliant parsers to extract the headers and payload of our messages. Under MIME, the body part of a message is separated from the headers via a blank line [REF]. This is often omitted in human posts. Furthermore, email clients and servers attach custom headers to processed email messages, so there is no standard set of headers we can match against. Finally, some of the messages downloaded by the crawler are not emails at all, so we also need a way to discard them.

We observe that correct headers follow a set pattern: \textit{``Header: content''}. Furthermore, there is at most one header per line and headers are placed on consecutive lines in the message. Using that observation, we propose a best-effort algorithm to address the problem above. We use a vocabulary $V$ of 144 verified headers (compiled ahead of time). Then, for each incoming message $M$, we use a regular expression to match the contents of the message against the standard set of headers $S$, such that $S = $\{$Subject, To, From, Reply$-$To\}$. If we fail to match at least three elements of $S$, we discard the message, as it is not a valid email. If we find a match, we then iterate over all lines in the message to find $L_{vmax}$, defined to be the last line that contains a header $\in V$. $L_{vmax}$ allows us to split the message into two segment -- headers and body. Lastly, we iterate over all lines in the headers segment and match each line against our header heuristic. If there is a match, we augment $V$, which gradually improves the performance of the algorithm.

Another problem with parsing incoming email messages is HTML. Popular web-based email services regularly use HTML to format outgoing messages. As these messages are multi-part, some are encoded in both \emph{text/plain} and \emph{text/html}, whilst others only offer \emph{text/html}. For messages available only in HTML format, we construct a HTML parse tree and remove all nodes that do not contain text. Finally, we strip all tags and convert any ampersand character codes to ASCII, where possible -- e.g.,  \emph{\&amp;} to \emph{\&}.

\subsection{Named-entity recognition and emails}
Named-entity recognition (NER) is an information extraction task which seeks to locate and classify entities in text into a set of predefined categories -- e.g., \textit{Persons, Locations, Organizations}. For our prototype system, we are interested only in the \emph{Persons} category, although other categories might have applications for certain scam variations.  By performing NER on the message body, we aim to determine the names of all actors in the scam with high accuracy and pass that information to the response generation component. This is a challenging problem, but there are systems available which offer high performance on these tasks.

One example is the Stanford Named Entity Recognizer [REF]. It is a Java implementation of a linear chain Conditional Random Field (CRF) classifier [REF, REF] and comes with large pre-trained models on the CoNLL 2003, MUC-6, MUC-7 and ACE named entity corpora. In this project we are specifically interested in the provided 3 class model, as it is reported to have a F$_{1}$ score of 90.36 for the \emph{Persons} class on the CoNNL 2003 dataset. Its features are presented in [TABLE]:

% Current word
% Previous word
% Next word
% Current word character n-gram
% Current POS tag
% Surrounding POS Tag Sequence
% Current Word Shape
% Surrounding Word Shape Sequence
% Presence of Word in Left Window (size 4)
% Presence of Word in Right Window (size 4)

Whilst the aforementioned entity corpora provide a robust coverage of the English language, we have also measured the performance of the model on AFF-specific emails on a small training set. The results are available in [CHAPTER]. 

Another important problem is to determine the relationships between named entities and extracted email addresses. As we explained in [BACKGROUND], a single scam message may involve multiple actors and contain multiple email addresses. It is necessary to pair actors with the correct email addresses when composing a reply. Failure to do so may result in replying to a non-existing address or addressing the scammer under the wrong name. Formally, given a set of named entities $N = $\{$n_{1}, n_{2},...,n_{m}$\} and a set of email addresses $E = $\{e_{1}, e_{2},...,e_{p}$\, compute all pairs $(n, e)$, such that each pair belongs to a unique actor in the scam. This is a difficult problem, but we can observe that in AFF scams email addresses are often a variation of a person's real name. Alternatively, they are located in proximity to a named entity.

We propose a two-round algorithm. In the first round, we remove the domain name from $\forall \in E$ and compute string similarity using bigrams $\forall (n, e)$ pairs $\in N, E$. Next, we rank all pairs by similarity score $Sc$ and place the top pairs in a bucket $B$, such that


we compute string similarity using bigrams for all $(n, e)$ pairs $\in N, E$. We rank 