\chapter{Evaluation}
T\his chapter contrains the evaluation of our prototype system. In [SECTION .1] we define the terminology we use in our results. [SECTION 1.2] focuses on intermediate results, i.e., results of various probabilistic tasks. Finally, we provide a discussion on the meaning of these results.

\section{Terminology}
Throughout this chapter, for the sake of clarity and brevity, we use the following terminology to present our results.
\begin{description}
\item[F$_{1}$] The F$_{1}$ score (also F-measure) is the harmonic mean of precision ($p$) and recall $(r)$, as defined by the formula: F$_{1} = \frac{2rp}{r + p}$.
\item[Macro F$_{1}$] The value is the result of averaging the F$_{1}$ scores for all classes.
\item[Micro F$_{1}$] The value represents a global calculation of F$_{1}$, regardless of class.
\item[Thread] Each thread is defined as a logical unit of all messages related to a single instance of a scam. Threads are proportional and contain messages from both the agent and the scammer.
\item[$\mathbf B_{rate}$] This is a measure of the bounce rate of our sample. It is defined as all threads containing messages that cannot be delivered (due to deleted email boxes, exceeded quota, etc.) over the total number of threads.
\item[$\mathbf P_{rate}$] This is a measure of the participation rate of our sample. It is defined as all threads that contain at least one reply from a scammer, over the total number of threads in the sample (excluding bounced threads).
\item[Other abbreviations] For brevity, in some tables we use the abbreviations \textit{TP, FN, FP, TN} to mean, respectively, \textit{True Positive, False Negative, False Positive, True Negative}.
\end{description}

\section{Intermediate results}
The intermediate results presented in this section measure the performance of probabilistic tasks in the classification and information extraction component.

\subsection{Scam variation classifier}
The scam variation classifier is trained on a classical 80:20 split of data from the 419 corpus. Our model achieves Macro F$_{1} = 0.81177$ and Micro F$_{1}= 0.77134$ on the $5,996$ data points in the validation set. A breakdown of the results is shown in [FIGURE].
\begin{center}
\scalebox{0.85}{
\begin{tabular}{| l*{6}{c}c |}
\hline
\textbf{Class} & \textbf{TP} & \textbf{FN} & \textbf{FP} & \textbf{TN} & \textbf{Precision} & \textbf{Recall} & \textbf{F$_{1}$} \\ \hline
ATM card & 106 & 50 & 55 & 5755 & 0.658 & 0.679 & 0.669 \\ \hline
Employment & 35 & 22 & 17 & 5892 & 0.673 & 0.614 & 0.642 \\ \hline
Next of kin & 962 & 98 & 99 & 4807 & 0.907 & 0.908 & 0.907 \\ \hline
Banking & 206 & 132 & 146 & 5482 & 0.585 & 0.609 & 0.597 \\ \hline
Fake cheques & 233 & 31 & 30 & 5672 & 0.886 & 0.883 & 0.884 \\ \hline
Orphans & 153 & 60 & 55 & 5698 & 0.736 & 0.718 & 0.727 \\ \hline
Business & 287 & 211 & 234 & 5234 & 0.551 & 0.576 & 0.563 \\ \hline
Government & 552 & 137 & 122 & 5155 & 0.819 & 0.801 & 0.810 \\ \hline
Refugees & 51 & 36 & 29 & 5850 & 0.638 & 0.586 & 0.611 \\ \hline
Church \& Charity & 79 & 26 & 15 & 5846 & 0.840 & 0.752 & 0.794 \\ \hline
Loans & 253 & 10 & 10 & 5693 & 0.962 & 0.962 & 0.962 \\ \hline
Romance & 134 & 14 & 26 & 5792 & 0.838 & 0.905 & 0.870 \\ \hline
Commodities & 35 & 18 & 11 & 5902 & 0.761 & 0.660 & 0.707 \\ \hline
Lottery & 801 & 30 & 53 & 5082 & 0.938 & 0.964 & 0.951 \\ \hline
WU \& MoneyGram & 92 & 23 & 31 & 5820 & 0.748 & 0.800 & 0.773 \\ \hline
Compensation & 275 & 60 & 70 & 5561 & 0.797 & 0.821 & 0.809 \\ \hline
Military & 77 & 9 & 6 & 5874 & 0.928 & 0.895 & 0.911 \\ \hline
Widow & 55 & 61 & 36 & 5814 & 0.604 & 0.474 & 0.531 \\ \hline
Delivery company & 50 & 26 & 17 & 5873 & 0.746 & 0.658 & 0.699 \\ \hline
Misc & 82 & 41 & 34 & 5809 & 0.707 & 0.667 & 0.686 \\ \hline
Dying people & 270 & 24 & 25 & 5647 & 0.915 & 0.918 & 0.917 \\ \hline
Mystery shopper & 55 & 4 & 2 & 5905 & 0.965 & 0.932 & 0.948 \\ \hline
\multicolumn{8}{ |r| }{\textbf{Macro F$_{1}$: 0.81177}} \\ \hline
\multicolumn{8}{ |r| }{\textbf{Micro F$_{1}$: 0.77134}} \\ \hline
\end{tabular}
}
\end{center}

\subsection{PQ classifier}
We evaluate the performance of the personal questions (PQ) classifier using 2-fold cross-validation on a set of 500 email messages. The averaged results are shown in [TABLE]. Note that since this is a binary classifier, the first two table rows are reciprocal.
\begin{center}
\scalebox{0.85}{
\begin{tabular}{| l*{6}{c}c |}
\hline 
\textbf{Class} & \textbf{TP} & \textbf{FN} & \textbf{FP} & \textbf{TN} & \textbf{Precision} & \textbf{Recall} & \textbf{F$_{1}$} \\ \hline
PQ & 96 & 26 & 7 & 121 & 0.932 & 0.787 & 0.853 \\ \hline
No PQ & 121 & 7 & 26 & 96 & 0.823 & 0.945 & 0.880 \\ \hline
\multicolumn{8}{ |r| }{\textbf{Macro F$_{1}$: 0.86800}} \\ \hline
\multicolumn{8}{ |r| }{\textbf{Micro F$_{1}$: 0.86667}} \\ \hline
\end{tabular}
}
\end{center}
\subsection{Named-entity recognition classifier}
As described in [SECTION], we use a CRF classifier with a pre-trained model on the CoNLL 2003, MUC-6, MUC-7 and ACE named entity corpora. In this section, we measure the model's performance on a validation set of 50 manually labelled messages (18655 words) from the 419 corpus. Whilst the sample is comparatively small, our time is limited and the model is already reported to achieve F$_{1} = 90.36$ for the \emph{Persons} class on the CoNNL 2003 dataset (see [SECTION]). The results are summarized in [TABLE]. Note that we do not include the \emph{Locations} and \emph{Organizations} classes, as they are not relevant to our use case.
\begin{center}
\scalebox{0.85}{
\begin{tabular}{| l*{6}{c}c |}
\hline 
\textbf{Class} & \textbf{TP} & \textbf{FN} & \textbf{FP} & \textbf{TN} & \textbf{Precision} & \textbf{Recall} & \textbf{F$_{1}$} \\ \hline
Persons & 354 & 85 & 31 & 18185 & 0.919 & 0.806 & 0.859 \\ \hline
\end{tabular}
}
\end{center}

\section{Conversation results}
In this section we present results of the conversations our system has maintained with scammers. We begin by reviewing our methodology. In Sections [SECTION][SECTION], we describe a number of interesting statistics.
\subsection{Methodology}
To measure the performance of our prototype system, we deployed it on a virtual private server ([SECTION]) and let it run continuously from 19 March to 28 March. Over the 10-day period, the system gathered and processed 348 scam instances in 19 classes. Of the 348 instances, 45 were in the set of currently supported classes -- \textit{Lottery, Orphans, Mystery shopper}. We present detailed statistics from these conversation threads in [SECTION]. To put our results in context, we provide several baseline measures, depending on the purpose of the experiment. For example, to measure the bounce rate of threads, we draw random samples from the remaining set of scam instances, in order to compare it with the sample obtained by the system.

\begin{center}
\scalebox{0.85}{
%\begin{tabular}{|l c|}
\begin{tabular}{l c}
  \hline
  \multicolumn{2}{c}{Experiment overview} \\
  \hline
  Duration & 10 days \\ %\hline
  Scam instances & 348 \\ %\hline
  Encountered classes & 19 \\ %\hline
  Threads & 45 \\ 
  \hline
\end{tabular}
}
\end{center}

\subsection{Bouce rate}
We m


a 10-day period from a virtual private server ([SECTION environemtn]). Over the course 

	3. Conversation results
		i. Methodology 3 samples. sample 1 organic from the client. sample 2, random subset of 
		0. Setup. 10-days. 348 + 45. Another sample where we manually responded to 20 messages. Say time is limited.
		i. Bounce rate
			- bounce rate for thread
			- bounce rate for baseline
		ii. Participation rate
			- braindead rate
			- test sample
			- other sample
		iv. Distribution of scam

{'church_and_charity': 3, 'next_of_kin': 45, 'lottery': 41, 'fake_cheques': 4, 'business': 41, 'dying_people': 9, 'orphans': 3, 'government': 18, 'misc': 18, 'romance': 56, 'banking': 7, 'compensation': 2, 'delivery_company': 14, 'commodities': 4, 'mystery_shopper': 1, 'western_union_and_moneygram': 7, 'loans': 61, 'atm_card': 7, 'widow': 7}

348 scam instances, 19 classes, 45 supported scam instances



		v.  Average thread length, words per thread
			- inclusive of all
			- existing emails
			- answered emails
			- human-sized sample 35/5 = 6.8


Possible other measures: In addition to average thread length, average number of words in thread? If it's easy to remove quoting etc., average % of first message replied to, histogram of thread length, average thread length by spam type ???






This chapter contains the evaluation 



design and all probabilistic classification tasks. In 

In addition, we also present results from all probabilistic classification tasks.

some intermediate results from 

the evaluation of the performance of our system, as well as 


This chapter contains the evaluation of the methods proposed in the previous
part, chapter 4. In section 5.1, we present the data sets and the methodology
used for testing. We give details about the parameter choices and set baseline
scores obtained by either classical NCA or simple linear projections, such as PCA,
LDA or RCA. Results for each individual method are presented in sections 5.3
and 5.4. A comparison of the methods is shown in subsection 5.3.4 using accuracy
versus time plots.
We should mention that we did not include all the results in this chapter to
prevent cluttering. Further experimentations can be found in appendix B

This chapter details the functionality and implementation of the response generation component. As emphasized in sections [SECTION], [SECTION], response generation depends on the outputs of the information extraction, classification, and identity generation components. 

