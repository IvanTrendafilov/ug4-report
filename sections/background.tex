\chapter{Background}
This chapter sets the context for our discussion. We start by exploring the dynamics of advance free fraud scams. Then we outline some of the most prominent work in the area of AFF prevention. At the end of this chapter, we explore notable conversational agents and their design.

\section{Inside a 419 scam}
To create an optimal system, it is important to understand how 419 scammers operate. In order to do this, we set up a simple experiment. We randomly selected 5 email messages that had been recently posted on 419eater.com, a popular anti-scam web site, and replied to all them from an anonymous email account, with the intention to keep the conversation going for as long as possible and try out different conversational tactics. Over the course of a week, we had received a total of 37 emails. The main observations from these conversations are summarized below:
\begin{enumerate}
\item Requests for detailed personal information, such as full name, address, telephone number, occupation, age, gender, passport photograph are very common.
\vspace{-5mm}
\item Scammers commonly use templates written ahead of time over the the first two email exchanges.
\vspace{-5mm}
\item It is common for scammers to share their targets' email addresses with other scammers -- e.g., via a mailing list.
\vspace{-5mm}
\item Often, scammers send their targets counterfeit documents -- e.g., certificates, passports, etc.
\vspace{-5mm}
\item Scams are often operated by more than one person (``actor") or, possibly, the same person assuming multiple identities.
\vspace{-5mm}
\item Scammers sometimes insist on phone numbers and attempt to call the target.
\vspace{-5mm}
\item Sometimes scammers do not respond to their target, despite initiating the conversation.
\end{enumerate}

Obs. (1) shows that our natural language model needs to take into account these requests for information and deal with them effectively. There are a few possible ways to do that. 

One approach would be to attempt to avoid or deflect these questions. The benefit of this approach is that it spares the agent from the requirement to store identity information about itself and does not actively deceive the scammer. This simplifies our design and implementation. However, a substantial drawback is that scammers use these questions as a signal of established trust. From the point of view of the scammer, if the target fails to comply with these requests, this is a strong indication to simply move on to the next viable target. 

A second approach is to let the agent invent and maintain an identity throughout the entire conversation thread. This is guaranteed to pass the initial screening. These strategies are discussed in more detail in [CHAPTER]

Obs. (2) shows the scale of AFF operations. It is clearly inefficient to compose each response individually, so scammers commonly prefer reusing templates as much as possible, whilst still making a few modifications -- e.g., adding the name of the target, changing aliases and altering country-specific details. Therefore, we will create strategies that aim to force the scammer to manually compose as many responses as possible. This is a very challenging task as it requires the agent to present the scammer with unexpected scenarios. Furthermore, it is not clear whether there is a metric which we can use to measure our success [Chapter].

Obs. (3) suggests a degree of organization in AFF operations. It is reasonable to suggest that groups of scammers work in coordination. The details of a victim, which is already proven to be susceptible, are valuable and appear to be traded among groups of scammers. In our experiment above, we received 3 additional messages which did not belong to any of the conversation threads we initiated. Whilst it is unfortunate that vulnerable people are repeatedly targeted, over an extended period this practice could supply our agent with additional scam instances. 

Obs. (4) refers to situations in which the scammer sends pictures of counterfeit documents to his target. The presence of an attachment in a document is a signal for the state of the conversation. The extension of the attached file makes it easy to determine whether the document is a picture or not, however objection recognition is required to determine if the picture contains a document, a person,  or neither. This task requires the addition of a image processing component to our system. Because this functionality is not central to our project, we will not implement it in our prototype, but will still use other heuristics, as described in [CHAPTER].

Obs. (5) means that conversation threads can involve multiple people (or multiple aliases of the same person). In order to continue the conversation, the system must be able to cluster the involved parties together into the correct thread, as well as handle the transition from addressing person $A$ to addressing person $B$. Failure to do so means we have to abandon any state information for that thread. We discuss a solution to the problem in [CHAPTER].

Obs. (6) describes variation of email 419 scams that transitions to a different medium -- the telephone. There is no useful way for us to receive or process phone calls, therefore we would prefer to either avoid or completely ignore these requests.

Obs. (7) has impact on how we can interpret our results during evaluation. Some email accounts get disabled, deleted, or become abandoned before the scammer has sent replies to all potential targets. Therefore, we will need to also measure a baseline performance. We describe this in [CHAPTER].

\section{Related work in advance fee fraud prevention}
Generic email spam has been the subject of a lot of research, including analyses of its economics and legality. A lot of effort has been spent on developing anti-spam techniques. Some of the most widely used techniques are client-side challenge/response systems, authentication and reputation mechanisms, DNS blacklists, pattern detection, rule-based filtering and statistical filtering. [REF] [REF] [REF]

Popular state of the art email services use a combination of these techniques to protect their users. An illustrative example is Yahoo! Mail. The service uses a rule-based filter on the sender side. Should a message trigger the filter, the user is prompted to respond to a CAPTCHA correctly before he can proceed with sending a message. On the receiver side, Yahoo! Mail combines its rule-based filter with a Bayesian filter, in addition to DNS blacklisting and domain authentication. 

Yahoo!, as well as the other top email providers -- Hotmail and Gmail, does not publish accuracy statistics of their spam filters. Nevertheless, the independent competitive insights firm Cascade Insights provides the most recent study to attempt to measure the accuracy of these providers. According to their methodology, they set up email accounts with these three email services, as well as an unfiltered account with a web hosting company. Next, they aggressively seeded these accounts by posting their addresses on blogs, public walls on social networks, various other target web sites, etc. Finally, they subscribed these accounts to a set of solicited, opt-in activities. At the end of the 5-week study period, they found that 58.33\% of the messages in the inbox folder of Yahoo Mail! were spam, compared to 48.88% and 48.57% for Gmail and Hotmail respectively. Nevertheless, it is important to consider these results holistically. It is not possible to measure the accuracy of anti-spam mechanisms via the outlined black box approach, due to the fact that all three of these providers reject delivery of messages that have a very high probability to be spam -- some of the test sample will be delivered to neither the inbox nor the spam folder. Despite this limitation, this study does allow us to conclude that spam remains to be a common problem for email users, even when using state of the art filters, as deployed by Yahoo!, Google, and Microsoft.

Common spam filtering techniques do not differentiate between generic and advance fee fraud spam. Nevertheless, there are methods designed specifically to combat AFF scams and are most often employed by online communities. Some popular communities have colorful names such as: \textit{419eater.com, The Scambaiter, 419 Hell, the Artists Against 419}. Their members describe their own actions as ``scam baiting'' and often consider the act a form of Internet vigilantism. 

The most common approach used by scam baiting communities is similar to the one discussed in this project -- emulate a potential victim and attempt to keep the scammer occupied for as long as possible. Additionally, many scambaiters will attempt to find out the scammer's personal information and give it to the authorities. Frequently, scambaiters will also contact hosting or Internet service providers and urge them to suspend accounts and fraudulent web sites. These approaches are somewhat successful, but limited in scale. Each scambaiter has to spend a proportional amount of time communicating with the scammer. As such, its impact is limited by the time and effort scambaiters are able to donate to the activity. Interestingly, scam baiting appears to also provide entertainment value, which explains its steady popularity, in spite of its obvious limitations.

A more radical approach to fighting AFF scams used to be popular with scam baiting communities until recently [REF]. This approach relied on the scambaiter's ability to obtain a scammer's IP address. Then, through assistance of the community, the scambaiter would proceed by initiating a Distributed Denial of Service (DDoS) attack on the subnetwork. Many variations of this approach are possible, including targeting phising web sites and open relay SMTP servers. Whilst this approach is effective in temporary disrupting a scammer's operation, it suffers from a few major drawbacks. First, scammers often host their operations on compromised servers. In these cases, DDoS attacks cause additional problems to network administrators with no involvement in AFF at all [REF]. Second, the practice is considered illegal in many countries, including the UK (as of 2006) [REF].

\section{Related work in conversational agents}
The origin of conversational agents can be tracked back to the 1960s. The most famous early example of simple natural language processing is the computer program ELIZA. The program can be described as a simple rule-based engine which attempts to mimic a Rogerian psychotherapist. It is implemented via a simple parser and substitution algorithm, which draws canned phrases from a script. ELIZA has no knowledge of state, context, reasoning, relationships, or the world [REF].

A more recent example is the computer program A.L.I.C.E., which won the 2004 Loebner Prize for most human-like chatterbot. Nearly half a decade later, A.L.I.C.E. is still based on pattern matching and word substitution into canned responses. The main improvements over ELIZA lie in its engineering. A.L.I.C.E. supports its own markup language -- AIML, which is used to input knowledge into the system. In its essence, AIML implements a hashmap of regular expressions to a set of possible responses. A simple clustering algorithm allows similar entities to be grouped together -- e.g., \emph{mother} and \emph{family}. Finally, a spelling and grammar correction algorithm attempts to transform user input before it is passed to the system's pattern matching engine. In its essence, A.L.I.C.E. can be thought of as a well-engineered extension of the principles set up by ELIZA.

Another well-known chatterbot is Cleverbot. Its design and operation are similar to the agents we have discussed so far, however it is novel in the way it obtains its script. The agent remembers responses it has received from conversations with people and is said to have a knowledge bank of 50 million contextual responses [REF]. In addition to that, the Cleverbot team performs offline filtering to determine which learned responses are usable.

Finally, perhaps the most widely used service that includes a conversational natural language interface is Apple's Siri. Whilst Siri's main design goal is to serve as an intelligent personal assistant, it also incorporates a set of interesting techniques in its natural language generation and understanding components. The agent is capable of evidential and probabilistic reasoning, and uses a combination of machine learning and rules to determine the correct state of the conversation. Each conversation is modelled as a finite state machine -- e.g., instructing the agent to create a new appointment transitions the agent into the \textit{creating appointment} state, which now allows transitions to the \textit{set date}, \textit{set appointment name}, \textit{set appointment location} and \emph{cancel} states. The agent also delegates different types of requests to various ontologies and backend service providers and is capable of reasoning about basic relations between entities.

In summary, conversational agents use a wide range of techniques for natural language processing. State of the art systems commonly use a combination of machine learning, text pattern matching, probabilistic reasoning and finite state models. Therefore, we believe it is possible to develop convincing conversational agents for domain-specific problems, such as advice fee fraud, by combining the techniques outlined above.